{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute if necessary\n",
    "# %%capture\n",
    "# !pip install numpy seaborn matplotlib pandas openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, Union, List\n",
    "import openml\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4: Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instrucciones__: A continuación hay una lista de funciones que debe implementar o tareas que debe desarrollar. La descripción de cada una de ellas se encuentra en la definición de cada una de las funciones. Cada función está marcada por &#x1F625;,  &#x1F643; o &#x1F921;. Las marcas indican:\n",
    "\n",
    "- &#x1F625;: Indican una entrega que debe ser hecha dentro de la misma sesión de la asignación. \n",
    "- &#x1F643;: Indican una entrega que puede ser hecha hasta la siguiente sesión.\n",
    "- &#x1F921;: Debe mostrar un avance en la misma sesión, pero la entrega puede ser hecha en la siguiente.\n",
    "\n",
    "Aquellas entregas parciales que no sean hechas el día de la asignación ya no serán válidas para las entregas totales, sin embargo, las entregas totales seguirán siendo válidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se incluye un dataset real. El dataset importado se llama LDPA y puede leer su descripción en la siguiente liga\n",
    "\n",
    "https://www.openml.org/d/1483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga la metadata del dataset\n",
    "dataset_info = openml.datasets.get_dataset(1483, download_data=False)\n",
    "\n",
    "# Obtiene el nombre de la columna a predecir\n",
    "target = dataset_info.default_target_attribute\n",
    "\n",
    "(\n",
    "    features, # Dataframe con las características que se pueden utilizar para predecir\n",
    "    outputs, # Columna a predecir\n",
    "    categorical_mask, # Máscara que indica que columnas de todas las características son categoricas\n",
    "    columns # Lista con el nombre de las características\n",
    ")= dataset_info.get_data(\n",
    "    dataset_format=\"dataframe\", target=target\n",
    ")\n",
    "\n",
    "categorical_mask = np.array(categorical_mask)\n",
    "columns = np.array(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La columna a predecir se llama '{target}'\")\n",
    "print(f\"Todas las características son {str(columns)}\")\n",
    "print(f\"Las características categóricas son {str(columns[categorical_mask])}\")\n",
    "print(f\"Las características numéricas son {str(columns[~categorical_mask])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión de las características\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realiza la partición de __train__ y __test__. __No debe utilizar la partición de test por ningún motivo__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    features, \n",
    "    outputs, \n",
    "    test_size=0.5, \n",
    "    random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 1 &#x1F921;\n",
    "\n",
    "Utilizando las técnicas vistas en clase, realicé su mejor esfuerzo para obtener el mejor modelo lineal posible utilizando __únicamente el conjunto de entrenamiento__ (X_train y y_train). Puede utilizar bibliotecas, pero únicamente las técnicas vistas en clase y debe ir generando métricas o visualizaciones que respalden su toma de decisiones. Debe tener e imprimir una estimación de $E_{out}$ utilizando su conjunto de entrenamiento. La métrica utilizada será la entropía cruzada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data set Information:\n",
    "\n",
    "People used for recording of the data were of the data were wearing four tags (ankle left, angle right, belt and chest). Each instance is a localization data for one of the tags. The tag can be identified by one of the attributes.\n",
    "\n",
    "##### Attribute Information:\n",
    "Instance Example: \n",
    "A01,020-000-033-111,633790226057226795,27.05.2009 14:03:25:723,4.292500972747803,2.0738532543182373,1.36650812625885,walking\n",
    "\n",
    "1. Sequence Name {A01,A02,A03,A04,A05,B01,B02,B03,B04,B05,C01,C02,C03,C04,C05,D01,D02,D03,D04,D05,E01,E02,E03,E04,E05} (Nominal)\n",
    "    - A, B, C, D, E = 5 people\n",
    "\n",
    "2. Tag identificator {010-000-024-033,020-000-033-111,020-000-032-221,010-000-030-096} (Nominal)\n",
    "    - ANKLE_LEFT = 010-000-024-033\n",
    "    - ANKLE_RIGHT = 010-000-030-096\n",
    "    - CHEST = 020-000-033-111\n",
    "    - BELT = 020-000-032-221\n",
    "\n",
    "3. timestamp (Numeric) all unique\n",
    "4. date FORMAT = dd.MM.yyyy HH:mm:ss:SSS (Date)\n",
    "5. x coordinate of the tag (Numeric)\n",
    "6. y coordinate of the tag (Numeric)\n",
    "7. z coordinate of the tag (Numeric)\n",
    "8. activity {walking,falling,'lying down',lying,'sitting down',sitting,'standing up from lying','on all fours','sitting on the ground','standing up from sitting','standing up from sitting on the ground'} (Nominal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(\"Filtro\")\n",
    "fig1.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # p, q = filtro(p, q)\n",
    "\n",
    "    ax = fig1.add_subplot(2, 2, i)\n",
    "    # ax.plot(p,q,\"g--\")\n",
    "    sns.histplot(x=X_train.iloc[:, i-1], kde=True, line_kws={'linestyle' : 'dashed',\n",
    "                                                    'linewidth' : '2'}, color='blue').lines[0].set_color('red')\n",
    "    ax.set_xlabel(\"valores\")\n",
    "    ax.set_ylabel(\"frecuencia\")\n",
    "    ax.set_title(\"{}\".format(X_train.columns[i-1]))\n",
    "    ax.grid(color='gray', linestyle='dashed', linewidth=1, alpha=0.4)\n",
    "    # Pintar los ejes pasando por (0,0)\n",
    "    ax.axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "# Creamos otra figura, se mostrar\n",
    "fig2 = plt.figure(\"n ** i\")\n",
    "fig2.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "# x = list(range(1, 10))\n",
    "for i in range(4, 7):\n",
    "    # y = npotencia(x, i)\n",
    "    ax = fig2.add_subplot(2, 2, i-3)\n",
    "    # ax.plot(x, y, \"r-.\")\n",
    "    sns.histplot(x=X_train.iloc[:, i], kde=True, line_kws={'linestyle' : 'dashed',\n",
    "                                                    'linewidth' : '2'}, color='blue').lines[0].set_color('red')\n",
    "    \n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"{}\".format(X_train.columns[i]))\n",
    "    ax.grid(color='gray', linestyle='dashed', linewidth=1, alpha=0.4)\n",
    "    ax.axhline(0, color='black', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos las clases de la variable a predecir\n",
    "plt.figure()\n",
    "sns.histplot(x=y_train, kde=True, line_kws={'linestyle' : 'dashed',\n",
    "                                                    'linewidth' : '2'}, color='orange').lines[0].set_color('red')\n",
    "plt.title(f'Datos de y_train')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.histplot(x=outputs, kde=True, line_kws={'linestyle' : 'dashed',\n",
    "                                                    'linewidth' : '2'}, color='green',).lines[0].set_color('red')\n",
    "plt.title(f'Datos originales, antes de separar')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver las clases estan mal distribuidos, por lo que no sería bueno seguir.\n",
    "\n",
    "Continuando con el preprosesamiento de los datos, aplicamos un one hot encode a los datos de entrenamiento para cambiar los valores categoricos a numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancía para realizar el one hot encode\n",
    "transformer = make_column_transformer(\n",
    "    (sklearn.preprocessing.OneHotEncoder(), ['V1', 'V2']),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Creamos un dataFrame con los datos ya convertidos a one hot \n",
    "x_train_one_hot = pd.DataFrame(transformer.fit_transform(X_train), columns=transformer.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos una regresión logistica multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia de pipeline\n",
    "pipe = Pipeline([('scaler', sklearn.preprocessing.StandardScaler()), \n",
    "                 ('logistic', LogisticRegression(class_weight=None, max_iter=1000, random_state=42, multi_class='multinomial'))])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "pipe.fit(x_train_one_hot, y_train)\n",
    "\n",
    "# Predecimos la probabilidad de que ocurra un valor\n",
    "valor_predicho = pipe.predict_proba(x_train_one_hot)\n",
    "\n",
    "# Obtenemos validación cruzada\n",
    "score = cross_val_score(pipe, x_train_one_hot, y_train, cv=5)\n",
    "print(f'El score de validación cruzada, es: {score}')\n",
    "\n",
    "# Obtenemos el valor de accuracy\n",
    "print(f'Con un accuracy score de: {sklearn.metrics.accuracy_score(y_train, pipe.predict(x_train_one_hot))}')\n",
    "\n",
    "# Obtenemos el valor de la entropia cruzada\n",
    "print(f'El valor de entropia cruzada es: {sklearn.metrics.log_loss(y_test, valor_predicho, labels=pipe.classes_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 2 &#x1F921;\n",
    "\n",
    "Evalue su modelo final en el conjunto de test (X_test y y_test). Su práctica será evaluada acorde a las técnicas aplicadas, la estimación de $E_{out}$, el valor de $E_{test}$, y contra las métricas obtenidas por sus compañeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancía para realizar el one hot encode\n",
    "transformer = make_column_transformer(\n",
    "    (sklearn.preprocessing.OneHotEncoder(), ['V1', 'V2']),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Creamos un dataFrame con los datos ya convertidos a one hot \n",
    "x_test_one_hot = pd.DataFrame(transformer.fit_transform(X_test), columns=transformer.get_feature_names_out())\n",
    "# x_test_one_hot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos otra instancia de pipeline\n",
    "# pip = Pipeline([('scaler', sklearn.preprocessing.StandardScaler()), \n",
    "#                  ('logistic', LogisticRegression(class_weight=None, max_iter=1000, random_state=42, multi_class='multinomial'))])\n",
    "\n",
    "pipe.fit(x_test_one_hot, y_test)\n",
    "\n",
    "# Predecimos la probabilidad de que ocurra un valor\n",
    "valor_predicho_test = pipe.predict_proba(x_test_one_hot)\n",
    "\n",
    "# Obtenemos validación cruzada\n",
    "score = cross_val_score(pipe, x_test_one_hot, y_test, cv=5)\n",
    "print(f'El score de validación cruzada, es: {score}')\n",
    "\n",
    "# Obtenemos el valor de accuracy\n",
    "print(f'Con un accuracy score de: {sklearn.metrics.accuracy_score(y_train, pipe.predict(x_test_one_hot))}')\n",
    "\n",
    "# Obtenemos el valor de la entropia cruzada\n",
    "print(f'El valor de entropia cruzada es: {sklearn.metrics.log_loss(y_test, valor_predicho_test, labels=pipe.classes_)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
